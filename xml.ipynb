{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 10\n",
    "---\n",
    "Hello All,\n",
    "\n",
    "Welcome to the DSCI 510's lab.\n",
    "\n",
    "Guidelines for the Lab:\n",
    "- You will be given the lab assignment in the start of the lab. You're supposed to complete it by the deadline stated on blackboard.  \n",
    "\n",
    "- You've to complete the assignments individually. If you are having trouble completing the assignment do let me know, I will clear your doubts and guide you but I'll not write code for you and no one else should :) !!!  \n",
    "\n",
    "- You have to fill in the code in this notebook and upload it to back to blackboard for submission. While doing this, make sure that all supporting files that you download from blackboard are in the same directory as this notebook.  \n",
    "\n",
    "- You are encouraged to look up resources online like python docs and stackoverflow. But, you are encouraged to look up the topics and not the questions themselves  \n",
    "\n",
    "- Your last submission will be counted towards your grade  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before attempting the below question, I recommend you to skim this xml documentation: https://docs.python.org/3/library/xml.etree.elementtree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.[30 points] \n",
    "---\n",
    "You are given a xml file with cities. See the attached file for its format. Takeaway from the format is that there is a data root tag which has child city tags in it. Each city tag may have multiple attributes and multiple tags in it. These tags and attributes are not mandated to be there in each city tag.  \n",
    "\n",
    "For this question, you are given a xml_file path and a `filters` dictionary as arguments of a function `filter_cities`. The key of the `filters` dictionary represents the attribute name of the city tag or the child tag name of the `city` tag. The value of that key represents the value of the corresponding attribute or text of the corresponding tag name.  \n",
    "\n",
    "This function should return the list of name of the cities that have matching values for all the attributes and tags given in the `filters`.  \n",
    "\n",
    "Assumptions: \n",
    "- All the attribute and tag names are combinedly unique.\n",
    "- All cities will have `name` tag in it. \n",
    "\n",
    "Note: While extracting the text from a tag, use `strip` to remove empty spaces and new lines.\n",
    "\n",
    "---\n",
    "Grading Rubric:  \n",
    "Using the sample xml file only.  \n",
    "- +10 - If function outputs correctly for `filters` that has only attribute name keys in it.  \n",
    "- +10 - If function outputs correctly for `filters` that has only tag name keys in it.  \n",
    "\n",
    "Using any kind of xml file with the above mentioned structure.  \n",
    "- +10 - If function outputs correctly for `filters` for all cases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T04:08:10.703288Z",
     "iopub.status.busy": "2021-11-05T04:08:10.703288Z",
     "iopub.status.idle": "2021-11-05T04:08:10.724230Z",
     "shell.execute_reply": "2021-11-05T04:08:10.723232Z",
     "shell.execute_reply.started": "2021-11-05T04:08:10.703288Z"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "# Your code goes here\n",
    "def filter_cities(xml_file, filters):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    keys = [i for i in filters]\n",
    "    attribs = list(set([i for city in root.findall(root[0].tag) for i in city.attrib.keys()]))\n",
    "    lst_total = []\n",
    "    for key in keys:\n",
    "        if key in attribs:\n",
    "            lst = []\n",
    "            for city in root.findall(root[0].tag):\n",
    "                try:\n",
    "                    if city.attrib[key]==filters[key]:\n",
    "                        lst.append(city.find('name').text.strip())\n",
    "                except:\n",
    "                    continue\n",
    "            lst_total.append(lst)\n",
    "        else:\n",
    "            lst = []\n",
    "            for city in root.findall(root[0].tag):\n",
    "                try:\n",
    "                    if city.find(key).text.strip()==filters[key]:\n",
    "                        lst.append(city.find('name').text.strip())\n",
    "                except:\n",
    "                    continue\n",
    "            lst_total.append(lst)\n",
    "    #common_city = list(set(lst_total[0]).intersection(*lst_total[1:]))\n",
    "    result = set(lst_total[0])\n",
    "    for i in lst_total[1:]:\n",
    "        result &= set(i)\n",
    "    common_city = list(result)\n",
    "         \n",
    "    return common_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T04:08:11.131332Z",
     "iopub.status.busy": "2021-11-05T04:08:11.130335Z",
     "iopub.status.idle": "2021-11-05T04:08:11.150284Z",
     "shell.execute_reply": "2021-11-05T04:08:11.149285Z",
     "shell.execute_reply.started": "2021-11-05T04:08:11.131332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Los Angeles', 'New York']\n"
     ]
    }
   ],
   "source": [
    "filters = {\n",
    "    \"class\": \"A\",\n",
    "    \"country\": \"USA\"\n",
    "}\n",
    "print(filter_cities(\"city.xml\", filters))\n",
    "# Expected output: ['Los Angeles', 'New York']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T00:58:33.666817Z",
     "iopub.status.busy": "2021-11-05T00:58:33.666817Z",
     "iopub.status.idle": "2021-11-05T00:58:33.682724Z",
     "shell.execute_reply": "2021-11-05T00:58:33.681780Z",
     "shell.execute_reply.started": "2021-11-05T00:58:33.666817Z"
    }
   },
   "outputs": [],
   "source": [
    "#intersection\n",
    "\n",
    "#1 reduce\n",
    "from functools import reduce\n",
    "L = [[1,2,3,4], [2,3,4,5], [3,4,5,6],[1,2,3,4,5,6]]\n",
    "reduce(lambda x,y : set(x) & set(y), L)\n",
    "\n",
    "#2 set\n",
    "L = [[1,2,3,4], [2,3,4,5], [3,4,5,6],[1,2,3,4,5,6]]\n",
    "set(L[0]).intersection(*L[1:])   # '*' means to break up list as separate arguments\n",
    "\n",
    "#3 set loop\n",
    "L = [[1,2,3,4], [2,3,4,5], [3,4,5,6],[1,2,3,4,5,6]]\n",
    "result = set(L[0])\n",
    "for i in L[1:]:\n",
    "    result &= set(i)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T21:30:40.160329Z",
     "iopub.status.busy": "2021-11-04T21:30:40.160031Z",
     "iopub.status.idle": "2021-11-04T21:30:40.182349Z",
     "shell.execute_reply": "2021-11-04T21:30:40.181271Z",
     "shell.execute_reply.started": "2021-11-04T21:30:40.160329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Los Angeles', 'New York']\n"
     ]
    }
   ],
   "source": [
    "#using lxml and creating xpath\n",
    "from lxml import etree\n",
    "def filter_cities(xml_file, filters):\n",
    "    with open(xml_file) as f:\n",
    "        tree = etree.parse(f)\n",
    "        \n",
    "    # construct xpath\n",
    "    #string = ''\n",
    "    #for i in filters:\n",
    "     #   if i=='class':\n",
    "      #      string += ' and @class={}'.format(\"'\"+filters[i]+\"'\")\n",
    "       # else:\n",
    "        #    string += ' and contains({},{})'.format(i,\"'\"+filters[i]+\"'\")\n",
    "    #string = string.strip().lstrip('and ')\n",
    "    \n",
    "    lst_xpath = []\n",
    "    for i in filters:\n",
    "        if i=='class':\n",
    "            lst_xpath.append('@class={}'.format(\"'\"+filters[i]+\"'\"))\n",
    "        else:\n",
    "            lst_xpath.append('contains({},{})'.format(i,\"'\"+filters[i]+\"'\"))\n",
    "    string = ' and '.join(lst_xpath)\n",
    "    \n",
    "    xpath = '//city[' + string + ']/name/text()'\n",
    "    \n",
    "    lst = [i.strip() for i in tree.xpath(xpath)]\n",
    "    return lst\n",
    "\n",
    "filters = {\n",
    "    \"class\": \"A\",\n",
    "    \"country\": \"USA\"\n",
    "    #\"state\"\n",
    "    #\"name\"\n",
    "    #\"county\"\n",
    "}\n",
    "print(filter_cities(\"city.xml\", filters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Question.[5 points] \n",
    "---\n",
    "To complete this question, you need the access key from the opencage website. To obtain that the procedure is:  \n",
    "1. open https://opencagedata.com/api\n",
    "2. Click on sign up for your free api key.\n",
    "3. Create a account and use the access key that you get from there for this question.\n",
    "\n",
    "You are given a xml_file and `filters` dictionary(Same as the above question(Also in the same format)). You have to get the latitude and longitude for the cities that you returned in the above question. Use the opencagedata api to do geocoding. Give the city name as the input and you will get a json response with lat and long information in it.   \n",
    "\n",
    "Input: str, dict  \n",
    "Return Output: List of tuples(each element in format (lat, long))  \n",
    "\n",
    "Note: Make use of the above question's function. If you cannot complete the above question, you can assume that it exists. \n",
    "\n",
    "---\n",
    "Grading Rubric: Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T03:18:06.715406Z",
     "iopub.status.busy": "2021-11-05T03:18:06.715406Z",
     "iopub.status.idle": "2021-11-05T03:18:10.288386Z",
     "shell.execute_reply": "2021-11-05T03:18:10.287384Z",
     "shell.execute_reply.started": "2021-11-05T03:18:06.715406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34.0536909, -118.242766), (40.7127281, -74.0060152)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def filter_cities_with_latlong(xml_file, filters):\n",
    "    lst = filter_cities(xml_file, filters)\n",
    "    lst_loc = []\n",
    "    for i in lst:\n",
    "        url = 'https://api.opencagedata.com/geocode/v1/json?key=2d8c00546c334deaaed81a61f798baf4&q={}&pretty=1'.format(i)\n",
    "        req = requests.get(url)\n",
    "        jsn = req.text\n",
    "        dic = json.loads(jsn)\n",
    "        longitude = dic['results'][0]['geometry']['lng']\n",
    "        latitude = dic['results'][0]['geometry']['lat']\n",
    "        lst_loc.append((latitude,longitude))\n",
    "    return lst_loc\n",
    "\n",
    "filters = {\n",
    "    \"class\": \"A\",\n",
    "    \"country\": \"USA\"\n",
    "}\n",
    "filter_cities_with_latlong(\"city.xml\", filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T18:58:55.095697Z",
     "iopub.status.busy": "2021-11-04T18:58:55.095697Z",
     "iopub.status.idle": "2021-11-04T18:58:56.956250Z",
     "shell.execute_reply": "2021-11-04T18:58:56.955000Z",
     "shell.execute_reply.started": "2021-11-04T18:58:55.095697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34.0536909, -118.242766), (40.7127281, -74.0060152)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution2 using OpenCageGeocode\n",
    "\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "def filter_cities_with_latlong(xml_file, filters):\n",
    "    key = '2d8c00546c334deaaed81a61f798baf4'\n",
    "    geocoder = OpenCageGeocode(key)\n",
    "    try: \n",
    "        lst = filter_cities(xml_file, filters)\n",
    "        lst_loc = []\n",
    "        for i in lst:\n",
    "            results = geocoder.geocode(i, no_annotations='1')           \n",
    "            if results and len(results):\n",
    "                longitude = results[0]['geometry']['lng']\n",
    "                latitude  = results[0]['geometry']['lat']\n",
    "                #print(u'%f;%f;%s' % (latitude, longitude, i))\n",
    "                # 34.053691;-118.242766;Los Angeles\n",
    "                # 40.712728;-74.006015;New York\n",
    "                lst_loc.append((latitude,longitude))\n",
    "            else:\n",
    "                sys.stderr.write(\"not found: %s\\n\" % address)\n",
    "    except IOError:\n",
    "        print('Error: File %s does not appear to exist.' % addressfile)\n",
    "    return lst_loc   \n",
    "\n",
    "\n",
    "filters = {\n",
    "    \"class\": \"A\",\n",
    "    \"country\": \"USA\"\n",
    "}\n",
    "filter_cities_with_latlong(\"city.xml\", filters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
